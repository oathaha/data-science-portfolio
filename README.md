# data-science-portfolio

This repository contains the implementations for my data science portfolio which can be found in this [link](https://sites.google.com/view/chanathip-pornprasit/). This portfolio contains the following projects:

 - [Chicago Road Accident Visualization](https://github.com/oathaha/data-science-portfolio/tree/df85187b19cf06ff3e3ae0f3b2affb48a3bc2b44/Chicago-road-accident-statistic-visualization)
 - [Assignment Completion Time Prediction]( https://github.com/oathaha/data-science-portfolio/tree/df85187b19cf06ff3e3ae0f3b2affb48a3bc2b44/Toloka-task-completion-prediction)
 - [Loan Application Status/Priority Prediction](https://github.com/oathaha/data-science-portfolio/tree/df85187b19cf06ff3e3ae0f3b2affb48a3bc2b44/Credit-Risk-Analysis)
 - [News Classification](https://github.com/oathaha/data-science-portfolio/tree/df85187b19cf06ff3e3ae0f3b2affb48a3bc2b44/Guardian-news-classification)
 - [Medium Article Title Generation](https://github.com/oathaha/data-science-portfolio/tree/df85187b19cf06ff3e3ae0f3b2affb48a3bc2b44/Medium-Articles-title-generation)

## Dataset
The dataset can be found in this [link](https://drive.google.com/drive/folders/1w_3rMmeEpQlBlHTCqupwSBHxwFoYXsEK?usp=drive_link)

## Fine-tuned Models
The fine-tuned models can be found in this [link] (...)

## Environment Setup

You can setup python environment by running the following command in the command prompt

    conda env create -f environment.yml

To run PySpark, you have to install Spark from this website: https://spark.apache.org/downloads.html first.

To run R script, you need to install Rstudio and the following packages: `tidyverse`, `ggsankey` and `ggmosaic`


